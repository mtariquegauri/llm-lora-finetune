# ğŸš€ Fine-Tuning LLMs with LoRA (PEFT)

This repo shows how to fine-tune large language models (LLMs) like **Falcon-7B** or **Mistral-7B** using **LoRA adapters** for parameter-efficient training.

---

## ğŸ“Œ What is LoRA?
- LLMs = billions of parameters â†’ too expensive to train fully.
- **LoRA** = adds small adapter layers, only those are trained.
- Result â†’ **cheap, fast fine-tuning** on consumer GPUs/Colab.

---

## ğŸ› ï¸ Tech Stack
- [ğŸ¤— Transformers](https://huggingface.co/docs/transformers)
- [ğŸ¤— PEFT](https://huggingface.co/docs/peft)
- [ğŸ¤— Datasets](https://huggingface.co/docs/datasets)
- [Colab / GPU]

---

## ğŸ“‚ Repo Structure
- `notebooks/train_lora.ipynb` â†’ quick Colab fine-tune demo  
- `src/train.py` â†’ script for training  
- `data/sample.json` â†’ toy dataset for testing  

---

## â–¶ï¸ Quick Start (Colab)

1. Install deps:
```bash
pip install -r requirements.txt
