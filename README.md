# llm-lora-finetune
This repo shows how to fine-tune large language models (LLMs) like **Falcon-7B** or **Mistral-7B** using **LoRA adapters** for parameter-efficient training.
